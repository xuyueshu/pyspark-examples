<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ChangeListManager">
    <list default="true" id="56cf1087-82e7-4807-84e4-91fbe0ecefa5" name="Default Changelist" comment="">
      <change beforePath="$PROJECT_DIR$/currentdate.py" beforeDir="false" afterPath="$PROJECT_DIR$/currentdate.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/pandas-pyspark-dataframe.py" beforeDir="false" afterPath="$PROJECT_DIR$/pandas-pyspark-dataframe.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/pyspark-add-new-column.py" beforeDir="false" afterPath="$PROJECT_DIR$/pyspark-add-new-column.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/pyspark-aggregate.py" beforeDir="false" afterPath="$PROJECT_DIR$/pyspark-aggregate.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/pyspark-array-string.py" beforeDir="false" afterPath="$PROJECT_DIR$/pyspark-array-string.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/pyspark-change-string-double.py" beforeDir="false" afterPath="$PROJECT_DIR$/pyspark-change-string-double.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/pyspark-convert-map-to-columns.py" beforeDir="false" afterPath="$PROJECT_DIR$/pyspark-convert-map-to-columns.py" afterDir="false" />
    </list>
    <option name="EXCLUDED_CONVERTED_TO_IGNORED" value="true" />
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="CoverageDataManager">
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_add_month.coverage" NAME="pyspark-add-month Coverage Results" MODIFIED="1649841444089" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_array_string.coverage" NAME="pyspark-array-string Coverage Results" MODIFIED="1649907243723" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_convert_columns_to_map.coverage" NAME="pyspark-convert_columns-to-map Coverage Results" MODIFIED="1649921504540" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$python_pandas.coverage" NAME="python-pandas Coverage Results" MODIFIED="1649945570644" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_window_functions.coverage" NAME="pyspark-window-functions Coverage Results" MODIFIED="1649945230908" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_arraytype.coverage" NAME="pyspark-arraytype Coverage Results" MODIFIED="1649907774066" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_cast_column.coverage" NAME="pyspark-cast-column Coverage Results" MODIFIED="1649917908043" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_create_dataframe.coverage" NAME="pyspark-create-dataframe Coverage Results" MODIFIED="1649921748155" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_count_distinct.coverage" NAME="pyspark-count-distinct Coverage Results" MODIFIED="1649921757927" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_expr.coverage" NAME="pyspark-expr Coverage Results" MODIFIED="1649923216542" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_groupby_sort.coverage" NAME="pyspark-groupby-sort Coverage Results" MODIFIED="1649924784583" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_aggregate.coverage" NAME="pyspark-aggregate Coverage Results" MODIFIED="1649905449440" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_convert_map_to_columns.coverage" NAME="pyspark-convert-map-to-columns Coverage Results" MODIFIED="1649921435509" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_change_string_double.coverage" NAME="pyspark-change-string-double Coverage Results" MODIFIED="1649918199786" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$convert_column_python_list.coverage" NAME="convert-column-python-list Coverage Results" MODIFIED="1649823941424" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_collect.coverage" NAME="pyspark-collect Coverage Results" MODIFIED="1649918420053" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_broadcast_dataframe.coverage" NAME="pyspark-broadcast-dataframe Coverage Results" MODIFIED="1649917492352" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_column_operations.coverage" NAME="pyspark-column-operations Coverage Results" MODIFIED="1649919803730" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pandas_pyspark_dataframe.coverage" NAME="pandas-pyspark-dataframe Coverage Results" MODIFIED="1649840990944" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_explode_nested_array.coverage" NAME="pyspark-explode-nested-array Coverage Results" MODIFIED="1649923045412" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_groupby.coverage" NAME="pyspark-groupby Coverage Results" MODIFIED="1649924466855" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_drop_column.coverage" NAME="pyspark-drop-column Coverage Results" MODIFIED="1649923199038" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_join.coverage" NAME="pyspark-join Coverage Results" MODIFIED="1649925114252" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_add_new_column.coverage" NAME="pyspark-add-new-column Coverage Results" MODIFIED="1649901793223" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_explode_array_map.coverage" NAME="pyspark-explode-array-map Coverage Results" MODIFIED="1649922504050" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$currentdate.coverage" NAME="currentdate Coverage Results" MODIFIED="1649839621188" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_column_functions.coverage" NAME="pyspark-column-functions Coverage Results" MODIFIED="1649919033499" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/pyspark_examples$pyspark_join_two_dataframes.coverage" NAME="pyspark-join-two-dataframes Coverage Results" MODIFIED="1649925135692" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
  </component>
  <component name="FileEditorManager">
    <leaf SIDE_TABS_SIZE_LIMIT_KEY="300">
      <file pinned="false" current-in-tab="true">
        <entry file="file://$PROJECT_DIR$/python-pandas.py">
          <provider selected="true" editor-type-id="text-editor">
            <state relative-caret-position="341">
              <caret line="18" lean-forward="true" selection-start-line="18" selection-end-line="18" />
            </state>
          </provider>
        </entry>
      </file>
    </leaf>
  </component>
  <component name="FindInProjectRecents">
    <findStrings>
      <find>arrayCol</find>
      <find>collect_list</find>
    </findStrings>
  </component>
  <component name="Git.Settings">
    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
  </component>
  <component name="IdeDocumentHistory">
    <option name="CHANGED_PATHS">
      <list>
        <option value="$PROJECT_DIR$/currentdate.py" />
        <option value="$PROJECT_DIR$/pandas-pyspark-dataframe.py" />
        <option value="$PROJECT_DIR$/pyspark-add-month.py" />
        <option value="$PROJECT_DIR$/pyspark-add-new-column.py" />
        <option value="$PROJECT_DIR$/pyspark-aggregate.py" />
        <option value="$PROJECT_DIR$/pyspark-array-string.py" />
        <option value="$PROJECT_DIR$/pyspark-change-string-double.py" />
        <option value="$PROJECT_DIR$/pyspark-convert-map-to-columns.py" />
      </list>
    </option>
  </component>
  <component name="ProjectFrameBounds" extendedState="6">
    <option name="x" value="175" />
    <option name="y" value="30" />
    <option name="width" value="980" />
    <option name="height" value="1040" />
  </component>
  <component name="ProjectView">
    <navigator proportions="" version="1">
      <foldersAlwaysOnTop value="true" />
    </navigator>
    <panes>
      <pane id="ProjectPane">
        <subPane>
          <expand>
            <path>
              <item name="pyspark-examples" type="b2602c69:ProjectViewProjectNode" />
              <item name="pyspark-examples" type="462c0819:PsiDirectoryNode" />
            </path>
          </expand>
          <select />
        </subPane>
      </pane>
      <pane id="Scope" />
    </panes>
  </component>
  <component name="PropertiesComponent">
    <property name="WebServerToolWindowFactoryState" value="false" />
    <property name="last_opened_file_path" value="$PROJECT_DIR$/../mypyproject" />
    <property name="nodejs_interpreter_path.stuck_in_default_project" value="undefined stuck path" />
    <property name="nodejs_npm_path_reset_for_default_project" value="true" />
    <property name="settings.editor.selected.configurable" value="com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable" />
  </component>
  <component name="RunDashboard">
    <option name="ruleStates">
      <list>
        <RuleState>
          <option name="name" value="ConfigurationTypeDashboardGroupingRule" />
        </RuleState>
        <RuleState>
          <option name="name" value="StatusDashboardGroupingRule" />
        </RuleState>
      </list>
    </option>
  </component>
  <component name="RunManager" selected="Python.python-pandas">
    <configuration name="pyspark-groupby-sort" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="pyspark-examples" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/pyspark-groupby-sort.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="pyspark-join-two-dataframes" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="pyspark-examples" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/pyspark-join-two-dataframes.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="pyspark-join" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="pyspark-examples" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/pyspark-join.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="pyspark-window-functions" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="pyspark-examples" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/pyspark-window-functions.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="python-pandas" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="pyspark-examples" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/python-pandas.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <recent_temporary>
      <list>
        <item itemvalue="Python.python-pandas" />
        <item itemvalue="Python.pyspark-window-functions" />
        <item itemvalue="Python.pyspark-join-two-dataframes" />
        <item itemvalue="Python.pyspark-join" />
        <item itemvalue="Python.pyspark-groupby-sort" />
      </list>
    </recent_temporary>
  </component>
  <component name="SvnConfiguration">
    <configuration />
  </component>
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="56cf1087-82e7-4807-84e4-91fbe0ecefa5" name="Default Changelist" comment="" />
      <created>1649406772963</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1649406772963</updated>
      <workItem from="1649406776473" duration="626000" />
      <workItem from="1649411491639" duration="712000" />
      <workItem from="1649823335720" duration="3511000" />
      <workItem from="1649837566284" duration="20092000" />
      <workItem from="1649922980532" duration="5420000" />
    </task>
    <servers />
  </component>
  <component name="TimeTrackingManager">
    <option name="totallyTimeSpent" value="30361000" />
  </component>
  <component name="ToolWindowManager">
    <frame x="-7" y="-7" width="1550" height="838" extended-state="6" />
    <editor active="true" />
    <layout>
      <window_info content_ui="combo" id="Project" order="0" visible="true" weight="0.1930295" />
      <window_info id="Structure" order="1" side_tool="true" weight="0.25" />
      <window_info id="Favorites" order="2" side_tool="true" />
      <window_info anchor="bottom" id="Message" order="0" />
      <window_info anchor="bottom" id="Find" order="1" />
      <window_info anchor="bottom" id="Run" order="2" weight="0.35835695" />
      <window_info anchor="bottom" id="Debug" order="3" weight="0.4" />
      <window_info anchor="bottom" id="Cvs" order="4" weight="0.25" />
      <window_info anchor="bottom" id="Inspection" order="5" weight="0.4" />
      <window_info anchor="bottom" id="TODO" order="6" />
      <window_info anchor="bottom" id="Docker" order="7" show_stripe_button="false" />
      <window_info anchor="bottom" id="Avro/Parquet Viewer" order="8" />
      <window_info anchor="bottom" id="Database Changes" order="9" />
      <window_info anchor="bottom" id="Event Log" order="10" side_tool="true" />
      <window_info anchor="bottom" id="Version Control" order="11" />
      <window_info anchor="bottom" id="Terminal" order="12" />
      <window_info anchor="bottom" id="Python Console" order="13" />
      <window_info anchor="right" id="Commander" internal_type="SLIDING" order="0" type="SLIDING" weight="0.4" />
      <window_info anchor="right" id="Ant Build" order="1" weight="0.25" />
      <window_info anchor="right" content_ui="combo" id="Hierarchy" order="2" weight="0.25" />
      <window_info anchor="right" id="SciView" order="3" weight="0.3297587" />
      <window_info anchor="right" id="Database" order="4" />
    </layout>
  </component>
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="1" />
  </component>
  <component name="editorHistoryManager">
    <entry file="file://$PROJECT_DIR$/pyspark-sql-case-when.py">
      <provider selected="true" editor-type-id="text-editor" />
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-split-function.py">
      <provider selected="true" editor-type-id="text-editor">
        <state>
          <caret column="23" selection-start-column="23" selection-end-column="23" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-time-diff.py">
      <provider selected="true" editor-type-id="text-editor" />
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-add-new-column.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="1356">
          <caret line="70" lean-forward="true" selection-start-line="70" selection-end-line="70" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-add-month.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="288">
          <caret line="12" column="11" lean-forward="true" selection-start-line="12" selection-start-column="11" selection-end-line="12" selection-end-column="11" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pandas-pyspark-dataframe.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="744">
          <caret line="31" column="20" selection-start-line="31" selection-start-column="9" selection-end-line="31" selection-end-column="20" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/currentdate.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="180">
          <caret line="20" column="29" selection-start-line="20" selection-start-column="29" selection-end-line="20" selection-end-column="29" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/convert-column-python-list.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="588">
          <caret line="37" column="14" lean-forward="true" selection-start-line="37" selection-start-column="14" selection-end-line="37" selection-end-column="14" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-aggregate.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="47">
          <caret line="15" column="13" lean-forward="true" selection-start-line="15" selection-start-column="13" selection-end-line="15" selection-end-column="13" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-array-string.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="245">
          <caret line="33" column="33" lean-forward="true" selection-start-line="33" selection-start-column="33" selection-end-line="33" selection-end-column="33" />
        </state>
      </provider>
    </entry>
    <entry file="file://D:/python/Anaconda3/envs/python37_spark24/Lib/site-packages/pyspark/sql/session.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="446">
          <caret line="756" column="8" selection-start-line="756" selection-start-column="8" selection-end-line="756" selection-end-column="8" />
        </state>
      </provider>
    </entry>
    <entry file="file://D:/python/Anaconda3/envs/python37_spark24/Lib/site-packages/pyspark/sql/types.pyi">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="206">
          <caret line="101" column="8" selection-start-line="101" selection-start-column="8" selection-end-line="101" selection-end-column="8" />
        </state>
      </provider>
    </entry>
    <entry file="file://D:/python/Anaconda3/envs/python37_spark24/Lib/site-packages/pyspark/sql/types.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="134">
          <caret line="284" selection-start-line="284" selection-end-line="284" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-arraytype.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="161">
          <caret line="39" column="71" selection-start-line="39" selection-start-column="65" selection-end-line="39" selection-end-column="71" />
          <folding>
            <element signature="e#60#96#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-broadcast-dataframe.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="89">
          <caret line="30" column="80" selection-start-line="30" selection-start-column="73" selection-end-line="30" selection-end-column="80" />
          <folding>
            <element signature="e#99#113#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-cast-column.py">
      <provider selected="true" editor-type-id="text-editor">
        <state>
          <caret line="19" column="14" selection-start-line="19" selection-start-column="3" selection-end-line="19" selection-end-column="14" />
        </state>
      </provider>
    </entry>
    <entry file="file://D:/python/Anaconda3/envs/python37_spark24/Lib/site-packages/pyspark/sql/functions.pyi">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="206">
          <caret line="154" column="4" selection-start-line="154" selection-start-column="4" selection-end-line="154" selection-end-column="4" />
          <folding>
            <element signature="e#48#75#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-change-string-double.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="144">
          <caret line="30" column="41" lean-forward="true" selection-start-line="30" selection-start-column="41" selection-end-line="30" selection-end-column="41" />
          <folding>
            <element signature="e#60#96#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-collect.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="339">
          <caret line="24" column="34" selection-start-line="24" selection-start-column="22" selection-end-line="24" selection-end-column="28" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-column-functions.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-49">
          <caret line="85" lean-forward="true" selection-start-line="85" selection-end-line="85" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-column-operations.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-313">
          <caret line="37" column="30" lean-forward="true" selection-start-line="37" selection-start-column="30" selection-end-line="37" selection-end-column="30" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-convert-map-to-columns.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="203">
          <caret line="43" column="14" lean-forward="true" selection-start-line="43" selection-start-column="14" selection-end-line="43" selection-end-column="14" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-convert_columns-to-map.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="197">
          <caret line="30" column="9" selection-start-line="30" selection-start-column="9" selection-end-line="30" selection-end-column="9" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-count-distinct.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="200">
          <caret line="32" column="36" lean-forward="true" selection-start-line="32" selection-start-column="36" selection-end-line="32" selection-end-column="36" />
        </state>
      </provider>
    </entry>
    <entry file="file://$USER_HOME$/.PyCharm2018.3/system/python_stubs/-1658092857/builtins.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-878">
          <caret line="3786" column="6" selection-start-line="3786" selection-start-column="6" selection-end-line="3786" selection-end-column="6" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-create-dataframe.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="248">
          <caret line="30" column="11" lean-forward="true" selection-start-line="30" selection-start-column="11" selection-end-line="30" selection-end-column="11" />
          <folding>
            <element signature="e#99#113#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-create-dataframe-dictionary.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-1000" />
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-empty-data-frame.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-504" />
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-explode-array-map.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="272">
          <caret line="34" column="56" selection-start-line="34" selection-start-column="52" selection-end-line="34" selection-end-column="56" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-explode-nested-array.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="32">
          <caret line="22" column="23" lean-forward="true" selection-start-line="22" selection-start-column="23" selection-end-line="22" selection-end-column="23" />
        </state>
      </provider>
    </entry>
    <entry file="file://D:/python/Anaconda3/envs/python37_spark24/Lib/site-packages/pyspark/sql/functions.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="24">
          <caret line="2093" column="4" selection-start-line="2093" selection-start-column="4" selection-end-line="2093" selection-end-column="4" />
          <folding>
            <element signature="e#828#838#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-drop-column.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-86">
          <caret line="26" column="27" lean-forward="true" selection-start-line="26" selection-start-column="27" selection-end-line="26" selection-end-column="27" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-expr.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="706">
          <caret line="32" column="10" lean-forward="true" selection-start-line="32" selection-start-column="10" selection-end-line="32" selection-end-column="10" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-drop-null.py">
      <provider selected="true" editor-type-id="text-editor" />
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-filter.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-624">
          <caret line="40" column="9" lean-forward="true" selection-start-line="40" selection-start-column="9" selection-end-line="40" selection-end-column="9" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-filter2.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-144" />
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-filter-null.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-720" />
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-fulter-null.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-360" />
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-groupby.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="227">
          <caret line="52" column="25" lean-forward="true" selection-start-line="52" selection-start-column="25" selection-end-line="52" selection-end-column="25" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-groupby-sort.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="144">
          <caret line="61" column="16" lean-forward="true" selection-start-line="61" selection-start-column="16" selection-end-line="61" selection-end-column="16" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-join.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="175">
          <caret line="77" column="88" selection-start-line="77" selection-start-column="81" selection-end-line="77" selection-end-column="88" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-join-two-dataframes.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="606">
          <caret line="67" lean-forward="true" selection-start-line="67" selection-end-line="67" />
        </state>
      </provider>
    </entry>
    <entry file="file://D:/python/Anaconda3/envs/python37_spark24/Lib/site-packages/pyspark/sql/dataframe.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-873">
          <caret line="1000" column="8" selection-start-line="1000" selection-start-column="8" selection-end-line="1000" selection-end-column="8" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-types.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="48">
          <caret line="40" column="4" lean-forward="true" selection-start-line="40" selection-start-column="4" selection-end-line="40" selection-end-column="4" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-union.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="222">
          <caret line="39" column="10" selection-start-line="39" selection-end-line="39" selection-end-column="10" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-update-column.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="102">
          <caret line="27" column="17" lean-forward="true" selection-start-line="27" selection-start-column="17" selection-end-line="27" selection-end-column="17" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-when-otherwise.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="246">
          <caret line="53" column="30" lean-forward="true" selection-start-line="53" selection-start-column="30" selection-end-line="53" selection-end-column="30" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-window-functions.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="448">
          <caret line="71" column="23" selection-start-line="71" selection-start-column="23" selection-end-line="71" selection-end-column="23" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/pyspark-withcolumn.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-728">
          <caret line="47" column="13" lean-forward="true" selection-start-line="47" selection-start-column="13" selection-end-line="47" selection-end-column="13" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/python-pandas.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="341">
          <caret line="18" lean-forward="true" selection-start-line="18" selection-end-line="18" />
        </state>
      </provider>
    </entry>
  </component>
</project>